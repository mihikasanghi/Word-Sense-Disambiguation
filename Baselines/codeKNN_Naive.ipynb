{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus.reader import SemcorCorpusReader\n",
    "from nltk.corpus import wordnet as wn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import tqdm \n",
    "import nltk\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Creating DataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/home2/arjun.dosajh/nltk_data/corpora/semcor')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find('corpora/semcor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_root = '/home2/arjun.dosajh/nltk_data/corpora/semcor'\n",
    "semcor_reader = SemcorCorpusReader(semcor_root, '.*', nltk.corpus.reader.wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = semcor_reader.tagged_sents(tag='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('DT', ['The']),\n",
       " Tree('group.n.01', [Tree('NE', [Tree('NNP', ['Fulton', 'County', 'Grand', 'Jury'])])]),\n",
       " Tree('say.v.01', [Tree('VB', ['said'])]),\n",
       " Tree('friday.n.01', [Tree('NN', ['Friday'])]),\n",
       " Tree('DT', ['an']),\n",
       " Tree('investigation.n.01', [Tree('NN', ['investigation'])]),\n",
       " Tree('IN', ['of']),\n",
       " Tree('atlanta.n.01', [Tree('NN', ['Atlanta'])]),\n",
       " Tree('POS', [\"'s\"]),\n",
       " Tree('recent.s.02', [Tree('JJ', ['recent'])]),\n",
       " Tree('primary_election.n.01', [Tree('NN', ['primary', 'election'])]),\n",
       " Tree('produce.v.04', [Tree('VB', ['produced'])]),\n",
       " Tree(None, ['``']),\n",
       " Tree('DT', ['no']),\n",
       " Tree('evidence.n.01', [Tree('NN', ['evidence'])]),\n",
       " Tree(None, [\"''\"]),\n",
       " Tree('IN', ['that']),\n",
       " Tree('DT', ['any']),\n",
       " Tree('irregularity.n.01', [Tree('NN', ['irregularities'])]),\n",
       " Tree('take_place.v.01', [Tree('VB', ['took', 'place'])]),\n",
       " Tree(None, ['.'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"72px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,40.0,72.0\" width=\"40px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">The</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('DT', ['The'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tree = tagged_sents[0]\n",
    "\n",
    "sample_tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,232.0,168.0\" width=\"232px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">group.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg><svg width=\"27.5862%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Fulton</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.7931%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"27.5862%\" x=\"27.5862%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">County</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.3793%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"24.1379%\" x=\"55.1724%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Grand</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.2414%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"20.6897%\" x=\"79.3103%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Jury</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"89.6552%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('group.n.01', [Tree('NE', [Tree('NNP', ['Fulton', 'County', 'Grand', 'Jury'])])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tree[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,104.0,120.0\" width=\"104px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">friday.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Friday</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('friday.n.01', [Tree('NN', ['Friday'])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tree[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,160.0,120.0\" width=\"160px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">investigation.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">investigation</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('investigation.n.01', [Tree('NN', ['investigation'])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tree[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_semcor_data(tagged_sents):\n",
    "    \"\"\"\n",
    "    Read SemCor data from tagged sentences and return a pandas DataFrame\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for sent_idx, sentence in enumerate(tagged_sents):\n",
    "        context_pos_sent = []\n",
    "        context_sent = []\n",
    "        for chunk in sentence:\n",
    "            if isinstance(chunk, nltk.Tree):\n",
    "                if chunk.label() == 'NE':  # Named Entity\n",
    "                    word = ' '.join([w for w in chunk.leaves()])\n",
    "                    pos = chunk.pos()[0][1]\n",
    "                    synset_full = 'NE'\n",
    "                else:\n",
    "                    word = chunk.leaves()[0]\n",
    "                    pos = chunk.label().split('.')[0] if chunk.label() else 'None'  # Extract POS from label\n",
    "                    synset_full = chunk.label() if chunk.label() and '.' in chunk.label() else None  # Extract synset if available\n",
    "                context_pos_sent.append(word + '_' + pos)\n",
    "                context_sent.append(word)\n",
    "            else:\n",
    "                context_pos_sent.append(chunk[0] + '_' + (chunk[1] if chunk[1] else 'None'))  # Handle None labels\n",
    "                context_sent.append(chunk[0])\n",
    "\n",
    "        context_pos = ' '.join(context_pos_sent)\n",
    "        context = ' '.join(context_sent)\n",
    "\n",
    "        for chunk in sentence:\n",
    "            if isinstance(chunk, nltk.Tree):\n",
    "                if chunk.label() == 'NE':  # Named Entity\n",
    "                    target_word = ' '.join([w for w in chunk.leaves()])\n",
    "                    pos = chunk.pos()[0][1]\n",
    "                    wn_index = None\n",
    "                    synset_full = 'NE'\n",
    "                else:\n",
    "                    target_word = chunk.leaves()[0]\n",
    "                    pos = chunk.label().split('.')[0] if chunk.label() else 'None'  # Extract POS from label\n",
    "                    synset_full = chunk.label() if chunk.label() and '.' in chunk.label() else None  # Extract synset if available\n",
    "                    wn_index = target_word + \"%\" + pos if synset_full else None\n",
    "            else:\n",
    "                target_word = chunk[0]\n",
    "                pos = chunk[1] if chunk[1] else 'None'  # Handle None labels\n",
    "                wn_index = None\n",
    "                synset_full = None\n",
    "\n",
    "            gloss = \"\"\n",
    "            is_proper_gloss = False\n",
    "            if synset_full is not None and synset_full != 'NE':\n",
    "                for sense in wn.synsets(target_word):\n",
    "                    if sense.name() == synset_full:\n",
    "                        gloss = sense.definition()\n",
    "                        is_proper_gloss = True\n",
    "                        break\n",
    "\n",
    "            data.append({\n",
    "                \"sentence_idx\": sent_idx,\n",
    "                \"context\": context,\n",
    "                \"context_pos\": context_pos,\n",
    "                \"target_word\": target_word,\n",
    "                \"pos\": pos,\n",
    "                \"gloss\": gloss,\n",
    "                \"is_proper_gloss\": is_proper_gloss,\n",
    "                \"wn_index\": wn_index,\n",
    "                \"sense_full\": synset_full,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_semcor_data(tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>group</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>Fulton%group</td>\n",
       "      <td>group.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>said</td>\n",
       "      <td>say</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>said%say</td>\n",
       "      <td>say.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>friday</td>\n",
       "      <td>the sixth day of the week; the fifth working day</td>\n",
       "      <td>True</td>\n",
       "      <td>Friday%friday</td>\n",
       "      <td>friday.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778582</th>\n",
       "      <td>37175</td>\n",
       "      <td>`` I can n't turn the studio into a gambling o...</td>\n",
       "      <td>``_None I_PRP can_MD n't_RB turn_turn_into the...</td>\n",
       "      <td>''</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778583</th>\n",
       "      <td>37175</td>\n",
       "      <td>`` I can n't turn the studio into a gambling o...</td>\n",
       "      <td>``_None I_PRP can_MD n't_RB turn_turn_into the...</td>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778584</th>\n",
       "      <td>37175</td>\n",
       "      <td>`` I can n't turn the studio into a gambling o...</td>\n",
       "      <td>``_None I_PRP can_MD n't_RB turn_turn_into the...</td>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778585</th>\n",
       "      <td>37175</td>\n",
       "      <td>`` I can n't turn the studio into a gambling o...</td>\n",
       "      <td>``_None I_PRP can_MD n't_RB turn_turn_into the...</td>\n",
       "      <td>said</td>\n",
       "      <td>say</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>said%say</td>\n",
       "      <td>say.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778586</th>\n",
       "      <td>37175</td>\n",
       "      <td>`` I can n't turn the studio into a gambling o...</td>\n",
       "      <td>``_None I_PRP can_MD n't_RB turn_turn_into the...</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778587 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_idx                                            context  \\\n",
       "0                  0  The Fulton said Friday an investigation of Atl...   \n",
       "1                  0  The Fulton said Friday an investigation of Atl...   \n",
       "2                  0  The Fulton said Friday an investigation of Atl...   \n",
       "3                  0  The Fulton said Friday an investigation of Atl...   \n",
       "4                  0  The Fulton said Friday an investigation of Atl...   \n",
       "...              ...                                                ...   \n",
       "778582         37175  `` I can n't turn the studio into a gambling o...   \n",
       "778583         37175  `` I can n't turn the studio into a gambling o...   \n",
       "778584         37175  `` I can n't turn the studio into a gambling o...   \n",
       "778585         37175  `` I can n't turn the studio into a gambling o...   \n",
       "778586         37175  `` I can n't turn the studio into a gambling o...   \n",
       "\n",
       "                                              context_pos target_word     pos  \\\n",
       "0       The_DT Fulton_group said_say Friday_friday an_...         The      DT   \n",
       "1       The_DT Fulton_group said_say Friday_friday an_...      Fulton   group   \n",
       "2       The_DT Fulton_group said_say Friday_friday an_...        said     say   \n",
       "3       The_DT Fulton_group said_say Friday_friday an_...      Friday  friday   \n",
       "4       The_DT Fulton_group said_say Friday_friday an_...          an      DT   \n",
       "...                                                   ...         ...     ...   \n",
       "778582  ``_None I_PRP can_MD n't_RB turn_turn_into the...          ''    None   \n",
       "778583  ``_None I_PRP can_MD n't_RB turn_turn_into the...           ,    None   \n",
       "778584  ``_None I_PRP can_MD n't_RB turn_turn_into the...           I     PRP   \n",
       "778585  ``_None I_PRP can_MD n't_RB turn_turn_into the...        said     say   \n",
       "778586  ``_None I_PRP can_MD n't_RB turn_turn_into the...           .    None   \n",
       "\n",
       "                                                   gloss  is_proper_gloss  \\\n",
       "0                                                                   False   \n",
       "1                                                                   False   \n",
       "2                                                                   False   \n",
       "3       the sixth day of the week; the fifth working day             True   \n",
       "4                                                                   False   \n",
       "...                                                  ...              ...   \n",
       "778582                                                              False   \n",
       "778583                                                              False   \n",
       "778584                                                              False   \n",
       "778585                                                              False   \n",
       "778586                                                              False   \n",
       "\n",
       "             wn_index   sense_full  \n",
       "0                None         None  \n",
       "1        Fulton%group   group.n.01  \n",
       "2            said%say     say.v.01  \n",
       "3       Friday%friday  friday.n.01  \n",
       "4                None         None  \n",
       "...               ...          ...  \n",
       "778582           None         None  \n",
       "778583           None         None  \n",
       "778584           None         None  \n",
       "778585       said%say     say.v.01  \n",
       "778586           None         None  \n",
       "\n",
       "[778587 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_idx                                                       0\n",
       "context            The Fulton said Friday an investigation of Atl...\n",
       "context_pos        The_DT Fulton_group said_say Friday_friday an_...\n",
       "target_word                                                      The\n",
       "pos                                                               DT\n",
       "gloss                                                               \n",
       "is_proper_gloss                                                False\n",
       "wn_index                                                        None\n",
       "sense_full                                                      None\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>friday</td>\n",
       "      <td>the sixth day of the week; the fifth working day</td>\n",
       "      <td>True</td>\n",
       "      <td>Friday%friday</td>\n",
       "      <td>friday.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>state capital and largest city of Georgia; chi...</td>\n",
       "      <td>True</td>\n",
       "      <td>Atlanta%atlanta</td>\n",
       "      <td>atlanta.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>produced</td>\n",
       "      <td>produce</td>\n",
       "      <td>bring out for display</td>\n",
       "      <td>True</td>\n",
       "      <td>produced%produce</td>\n",
       "      <td>produce.v.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>evidence</td>\n",
       "      <td>evidence</td>\n",
       "      <td>your basis for belief or disbelief; knowledge ...</td>\n",
       "      <td>True</td>\n",
       "      <td>evidence%evidence</td>\n",
       "      <td>evidence.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>jury</td>\n",
       "      <td>jury</td>\n",
       "      <td>a body of citizens sworn to give a true verdic...</td>\n",
       "      <td>True</td>\n",
       "      <td>jury%jury</td>\n",
       "      <td>jury.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778522</th>\n",
       "      <td>37171</td>\n",
       "      <td>`` If I could only think something at the stud...</td>\n",
       "      <td>``_None If_IN I_PRP could_MD only_RB think_thi...</td>\n",
       "      <td>absorb</td>\n",
       "      <td>absorb</td>\n",
       "      <td>take in, also metaphorically</td>\n",
       "      <td>True</td>\n",
       "      <td>absorb%absorb</td>\n",
       "      <td>absorb.v.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778533</th>\n",
       "      <td>37172</td>\n",
       "      <td>`` What is Letch interested in '' ?</td>\n",
       "      <td>``_None What_WP is_be Letch_NNP interested_JJ ...</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>True</td>\n",
       "      <td>is%be</td>\n",
       "      <td>be.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778558</th>\n",
       "      <td>37174</td>\n",
       "      <td>Her reply stung me , but this was too importan...</td>\n",
       "      <td>Her_PRP$ reply_NN stung_sting me_PRP ,_None bu...</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>True</td>\n",
       "      <td>was%be</td>\n",
       "      <td>be.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778562</th>\n",
       "      <td>37174</td>\n",
       "      <td>Her reply stung me , but this was too importan...</td>\n",
       "      <td>Her_PRP$ reply_NN stung_sting me_PRP ,_None bu...</td>\n",
       "      <td>let</td>\n",
       "      <td>let</td>\n",
       "      <td>make it possible through a specific action or ...</td>\n",
       "      <td>True</td>\n",
       "      <td>let%let</td>\n",
       "      <td>let.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778565</th>\n",
       "      <td>37174</td>\n",
       "      <td>Her reply stung me , but this was too importan...</td>\n",
       "      <td>Her_PRP$ reply_NN stung_sting me_PRP ,_None bu...</td>\n",
       "      <td>make</td>\n",
       "      <td>make</td>\n",
       "      <td>engage in</td>\n",
       "      <td>True</td>\n",
       "      <td>make%make</td>\n",
       "      <td>make.v.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151452 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_idx                                            context  \\\n",
       "3                  0  The Fulton said Friday an investigation of Atl...   \n",
       "7                  0  The Fulton said Friday an investigation of Atl...   \n",
       "11                 0  The Fulton said Friday an investigation of Atl...   \n",
       "14                 0  The Fulton said Friday an investigation of Atl...   \n",
       "22                 1  The jury further said in term end presentments...   \n",
       "...              ...                                                ...   \n",
       "778522         37171  `` If I could only think something at the stud...   \n",
       "778533         37172                `` What is Letch interested in '' ?   \n",
       "778558         37174  Her reply stung me , but this was too importan...   \n",
       "778562         37174  Her reply stung me , but this was too importan...   \n",
       "778565         37174  Her reply stung me , but this was too importan...   \n",
       "\n",
       "                                              context_pos target_word  \\\n",
       "3       The_DT Fulton_group said_say Friday_friday an_...      Friday   \n",
       "7       The_DT Fulton_group said_say Friday_friday an_...     Atlanta   \n",
       "11      The_DT Fulton_group said_say Friday_friday an_...    produced   \n",
       "14      The_DT Fulton_group said_say Friday_friday an_...    evidence   \n",
       "22      The_DT jury_jury further_far said_say in_IN te...        jury   \n",
       "...                                                   ...         ...   \n",
       "778522  ``_None If_IN I_PRP could_MD only_RB think_thi...      absorb   \n",
       "778533  ``_None What_WP is_be Letch_NNP interested_JJ ...          is   \n",
       "778558  Her_PRP$ reply_NN stung_sting me_PRP ,_None bu...         was   \n",
       "778562  Her_PRP$ reply_NN stung_sting me_PRP ,_None bu...         let   \n",
       "778565  Her_PRP$ reply_NN stung_sting me_PRP ,_None bu...        make   \n",
       "\n",
       "             pos                                              gloss  \\\n",
       "3         friday   the sixth day of the week; the fifth working day   \n",
       "7        atlanta  state capital and largest city of Georgia; chi...   \n",
       "11       produce                              bring out for display   \n",
       "14      evidence  your basis for belief or disbelief; knowledge ...   \n",
       "22          jury  a body of citizens sworn to give a true verdic...   \n",
       "...          ...                                                ...   \n",
       "778522    absorb                       take in, also metaphorically   \n",
       "778533        be  have the quality of being; (copula, used with ...   \n",
       "778558        be  have the quality of being; (copula, used with ...   \n",
       "778562       let  make it possible through a specific action or ...   \n",
       "778565      make                                          engage in   \n",
       "\n",
       "        is_proper_gloss           wn_index     sense_full  \n",
       "3                  True      Friday%friday    friday.n.01  \n",
       "7                  True    Atlanta%atlanta   atlanta.n.01  \n",
       "11                 True   produced%produce   produce.v.04  \n",
       "14                 True  evidence%evidence  evidence.n.01  \n",
       "22                 True          jury%jury      jury.n.01  \n",
       "...                 ...                ...            ...  \n",
       "778522             True      absorb%absorb    absorb.v.04  \n",
       "778533             True              is%be        be.v.01  \n",
       "778558             True             was%be        be.v.01  \n",
       "778562             True            let%let       let.v.01  \n",
       "778565             True          make%make      make.v.01  \n",
       "\n",
       "[151452 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_proper_gloss'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_semcor_data(dataset):\n",
    "    cnt = 0\n",
    "    data = dataset.copy()\n",
    "    \n",
    "    for i, row in tqdm.tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        context_words = nltk.word_tokenize(row[\"context\"])\n",
    "        context_pos_words = nltk.word_tokenize(row[\"context_pos\"])\n",
    "        \n",
    "        if row[\"wn_index\"] is not None:\n",
    "            target_word_lemma = row[\"wn_index\"].split(\"%\")[0]\n",
    "            synsets = wn.synsets(target_word_lemma)\n",
    "        else:\n",
    "            target_word_lemma = None\n",
    "            synsets = []\n",
    "        \n",
    "        # trg_idx = int(row['target_word'][1:])\n",
    "        # trg_idx is the index of context at which target word is present\n",
    "        # print(row['context'])\n",
    "        if row['target_word'] not in context_words:\n",
    "            continue\n",
    "        else:\n",
    "            trg_idx = context_words.index(row['target_word'])\n",
    "            target_word = 'w' + str(trg_idx)\n",
    "            row['target_word'] = target_word\n",
    "            df.loc[i, 'target_word'] = target_word\n",
    "            \n",
    "        \n",
    "        \n",
    "        if len(synsets) > 0:\n",
    "            target_synset = synsets[0]\n",
    "        else:\n",
    "            target_synset = None\n",
    "        \n",
    "        window_start = max(0, trg_idx - 10)\n",
    "        window_end = min(len(context_words), trg_idx + 10)\n",
    "        context_window = context_words[window_start:trg_idx] + context_words[trg_idx+1:window_end]\n",
    "        context_window_pos = context_pos_words[window_start:trg_idx] + context_pos_words[trg_idx+1:window_end]\n",
    "        \n",
    "        if len(context_window) == 0:\n",
    "            cnt = cnt + 1\n",
    "        \n",
    "        data.at[i, 'context'] = ' '.join(context_window)\n",
    "        data.at[i, 'context_pos'] = ' '.join(context_window_pos)\n",
    "    \n",
    "    data = data[data[\"gloss\"]!=\"\"]\n",
    "    data = data[data[\"context_pos\"]!=\"\"]\n",
    "    data = data[data[\"context\"]!=\"\"]\n",
    "    \n",
    "    print(\"Number of proper glosses: \", data[\"is_proper_gloss\"].sum())\n",
    "    print(cnt)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [07:47<00:00, 107.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proper glosses:  15260\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_semcor_data(df[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w3</td>\n",
       "      <td>friday</td>\n",
       "      <td>the sixth day of the week; the fifth working day</td>\n",
       "      <td>True</td>\n",
       "      <td>Friday%friday</td>\n",
       "      <td>friday.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w7</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>state capital and largest city of Georgia; chi...</td>\n",
       "      <td>True</td>\n",
       "      <td>Atlanta%atlanta</td>\n",
       "      <td>atlanta.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w11</td>\n",
       "      <td>produce</td>\n",
       "      <td>bring out for display</td>\n",
       "      <td>True</td>\n",
       "      <td>produced%produce</td>\n",
       "      <td>produce.v.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w14</td>\n",
       "      <td>evidence</td>\n",
       "      <td>your basis for belief or disbelief; knowledge ...</td>\n",
       "      <td>True</td>\n",
       "      <td>evidence%evidence</td>\n",
       "      <td>evidence.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w1</td>\n",
       "      <td>jury</td>\n",
       "      <td>a body of citizens sworn to give a true verdic...</td>\n",
       "      <td>True</td>\n",
       "      <td>jury%jury</td>\n",
       "      <td>jury.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>2198</td>\n",
       "      <td>neon superimposed on a rectangular base - to t...</td>\n",
       "      <td>neon_neon_tube superimposed_superimpose on_IN ...</td>\n",
       "      <td>diseased</td>\n",
       "      <td>diseased</td>\n",
       "      <td>caused by or altered by or manifesting disease...</td>\n",
       "      <td>True</td>\n",
       "      <td>diseased%diseased</td>\n",
       "      <td>diseased.s.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>2198</td>\n",
       "      <td>base - to the supposedly diseased portions of ...</td>\n",
       "      <td>base_base -_None to_TO the_DT supposedly_suppo...</td>\n",
       "      <td>body</td>\n",
       "      <td>body</td>\n",
       "      <td>the entire structure of an organism (an animal...</td>\n",
       "      <td>True</td>\n",
       "      <td>body%body</td>\n",
       "      <td>body.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>2198</td>\n",
       "      <td>diseased portions of Mrs. 's body , Lee kept a...</td>\n",
       "      <td>diseased_diseased portions_portion of_IN Mrs._...</td>\n",
       "      <td>steady</td>\n",
       "      <td>steady</td>\n",
       "      <td>not subject to change or variation especially ...</td>\n",
       "      <td>True</td>\n",
       "      <td>steady%steady</td>\n",
       "      <td>steady.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>2198</td>\n",
       "      <td>Mrs. 's body , Lee kept a steady stream of sci...</td>\n",
       "      <td>Mrs._person 's_POS body_body , _None Lee_perso...</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>(often used in combination) not genuine but ha...</td>\n",
       "      <td>True</td>\n",
       "      <td>pseudo%pseudo</td>\n",
       "      <td>pseudo.s.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>2198</td>\n",
       "      <td>'s body , Lee kept a steady stream of pseudo m...</td>\n",
       "      <td>'s_POS body_body , _None Lee_person kept_keep_...</td>\n",
       "      <td>scientific</td>\n",
       "      <td>scientific</td>\n",
       "      <td>conforming with the principles or methods used...</td>\n",
       "      <td>True</td>\n",
       "      <td>scientific%scientific</td>\n",
       "      <td>scientific.a.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15260 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_idx                                            context  \\\n",
       "3                 0  The Fulton said Friday an investigation of Atl...   \n",
       "7                 0  The Fulton said Friday an investigation of Atl...   \n",
       "11                0  The Fulton said Friday an investigation of Atl...   \n",
       "14                0  The Fulton said Friday an investigation of Atl...   \n",
       "22                1  The jury further said in term end presentments...   \n",
       "...             ...                                                ...   \n",
       "49983          2198  neon superimposed on a rectangular base - to t...   \n",
       "49988          2198  base - to the supposedly diseased portions of ...   \n",
       "49993          2198  diseased portions of Mrs. 's body , Lee kept a...   \n",
       "49996          2198  Mrs. 's body , Lee kept a steady stream of sci...   \n",
       "49997          2198  's body , Lee kept a steady stream of pseudo m...   \n",
       "\n",
       "                                             context_pos target_word  \\\n",
       "3      The_DT Fulton_group said_say Friday_friday an_...          w3   \n",
       "7      The_DT Fulton_group said_say Friday_friday an_...          w7   \n",
       "11     The_DT Fulton_group said_say Friday_friday an_...         w11   \n",
       "14     The_DT Fulton_group said_say Friday_friday an_...         w14   \n",
       "22     The_DT jury_jury further_far said_say in_IN te...          w1   \n",
       "...                                                  ...         ...   \n",
       "49983  neon_neon_tube superimposed_superimpose on_IN ...    diseased   \n",
       "49988  base_base -_None to_TO the_DT supposedly_suppo...        body   \n",
       "49993  diseased_diseased portions_portion of_IN Mrs._...      steady   \n",
       "49996  Mrs._person 's_POS body_body , _None Lee_perso...      pseudo   \n",
       "49997  's_POS body_body , _None Lee_person kept_keep_...  scientific   \n",
       "\n",
       "              pos                                              gloss  \\\n",
       "3          friday   the sixth day of the week; the fifth working day   \n",
       "7         atlanta  state capital and largest city of Georgia; chi...   \n",
       "11        produce                              bring out for display   \n",
       "14       evidence  your basis for belief or disbelief; knowledge ...   \n",
       "22           jury  a body of citizens sworn to give a true verdic...   \n",
       "...           ...                                                ...   \n",
       "49983    diseased  caused by or altered by or manifesting disease...   \n",
       "49988        body  the entire structure of an organism (an animal...   \n",
       "49993      steady  not subject to change or variation especially ...   \n",
       "49996      pseudo  (often used in combination) not genuine but ha...   \n",
       "49997  scientific  conforming with the principles or methods used...   \n",
       "\n",
       "       is_proper_gloss               wn_index       sense_full  \n",
       "3                 True          Friday%friday      friday.n.01  \n",
       "7                 True        Atlanta%atlanta     atlanta.n.01  \n",
       "11                True       produced%produce     produce.v.04  \n",
       "14                True      evidence%evidence    evidence.n.01  \n",
       "22                True              jury%jury        jury.n.01  \n",
       "...                ...                    ...              ...  \n",
       "49983             True      diseased%diseased    diseased.s.01  \n",
       "49988             True              body%body        body.n.01  \n",
       "49993             True          steady%steady      steady.a.01  \n",
       "49996             True          pseudo%pseudo      pseudo.s.01  \n",
       "49997             True  scientific%scientific  scientific.a.02  \n",
       "\n",
       "[15260 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"sense_full\"]!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w3</td>\n",
       "      <td>friday</td>\n",
       "      <td>the sixth day of the week; the fifth working day</td>\n",
       "      <td>True</td>\n",
       "      <td>Friday%friday</td>\n",
       "      <td>friday.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w7</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>state capital and largest city of Georgia; chi...</td>\n",
       "      <td>True</td>\n",
       "      <td>Atlanta%atlanta</td>\n",
       "      <td>atlanta.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w11</td>\n",
       "      <td>produce</td>\n",
       "      <td>bring out for display</td>\n",
       "      <td>True</td>\n",
       "      <td>produced%produce</td>\n",
       "      <td>produce.v.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>The Fulton said Friday an investigation of Atl...</td>\n",
       "      <td>The_DT Fulton_group said_say Friday_friday an_...</td>\n",
       "      <td>w14</td>\n",
       "      <td>evidence</td>\n",
       "      <td>your basis for belief or disbelief; knowledge ...</td>\n",
       "      <td>True</td>\n",
       "      <td>evidence%evidence</td>\n",
       "      <td>evidence.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w1</td>\n",
       "      <td>jury</td>\n",
       "      <td>a body of citizens sworn to give a true verdic...</td>\n",
       "      <td>True</td>\n",
       "      <td>jury%jury</td>\n",
       "      <td>jury.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w2</td>\n",
       "      <td>far</td>\n",
       "      <td>at or to or from a great distance in space</td>\n",
       "      <td>True</td>\n",
       "      <td>further%far</td>\n",
       "      <td>far.r.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w5</td>\n",
       "      <td>term</td>\n",
       "      <td>a limited period of time</td>\n",
       "      <td>True</td>\n",
       "      <td>term%term</td>\n",
       "      <td>term.n.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w6</td>\n",
       "      <td>end</td>\n",
       "      <td>the point in time at which something ends</td>\n",
       "      <td>True</td>\n",
       "      <td>end%end</td>\n",
       "      <td>end.n.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w7</td>\n",
       "      <td>presentment</td>\n",
       "      <td>an accusation of crime made by a grand jury on...</td>\n",
       "      <td>True</td>\n",
       "      <td>presentments%presentment</td>\n",
       "      <td>presentment.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w18</td>\n",
       "      <td>election</td>\n",
       "      <td>a vote to select the winner of a position or p...</td>\n",
       "      <td>True</td>\n",
       "      <td>election%election</td>\n",
       "      <td>election.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w21</td>\n",
       "      <td>deserve</td>\n",
       "      <td>be worthy or deserving</td>\n",
       "      <td>True</td>\n",
       "      <td>deserves%deserve</td>\n",
       "      <td>deserve.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w23</td>\n",
       "      <td>praise</td>\n",
       "      <td>an expression of approval and commendation</td>\n",
       "      <td>True</td>\n",
       "      <td>praise%praise</td>\n",
       "      <td>praise.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w25</td>\n",
       "      <td>thanks</td>\n",
       "      <td>an acknowledgment of appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>thanks%thanks</td>\n",
       "      <td>thanks.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w32</td>\n",
       "      <td>manner</td>\n",
       "      <td>how something is done or how it happens</td>\n",
       "      <td>True</td>\n",
       "      <td>manner%manner</td>\n",
       "      <td>manner.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w18</td>\n",
       "      <td>election</td>\n",
       "      <td>a vote to select the winner of a position or p...</td>\n",
       "      <td>True</td>\n",
       "      <td>election%election</td>\n",
       "      <td>election.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>The jury further said in term end presentments...</td>\n",
       "      <td>The_DT jury_jury further_far said_say in_IN te...</td>\n",
       "      <td>w38</td>\n",
       "      <td>conduct</td>\n",
       "      <td>direct the course of; manage or control</td>\n",
       "      <td>True</td>\n",
       "      <td>conducted%conduct</td>\n",
       "      <td>conduct.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>The September October term jury had been charg...</td>\n",
       "      <td>The_DT September_september October_october ter...</td>\n",
       "      <td>w1</td>\n",
       "      <td>september</td>\n",
       "      <td>the month following August and preceding October</td>\n",
       "      <td>True</td>\n",
       "      <td>September%september</td>\n",
       "      <td>september.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>The September October term jury had been charg...</td>\n",
       "      <td>The_DT September_september October_october ter...</td>\n",
       "      <td>w2</td>\n",
       "      <td>october</td>\n",
       "      <td>the month following September and preceding No...</td>\n",
       "      <td>True</td>\n",
       "      <td>October%october</td>\n",
       "      <td>october.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>The September October term jury had been charg...</td>\n",
       "      <td>The_DT September_september October_october ter...</td>\n",
       "      <td>w3</td>\n",
       "      <td>term</td>\n",
       "      <td>a limited period of time</td>\n",
       "      <td>True</td>\n",
       "      <td>term%term</td>\n",
       "      <td>term.n.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>The September October term jury had been charg...</td>\n",
       "      <td>The_DT September_september October_october ter...</td>\n",
       "      <td>w4</td>\n",
       "      <td>jury</td>\n",
       "      <td>a body of citizens sworn to give a true verdic...</td>\n",
       "      <td>True</td>\n",
       "      <td>jury%jury</td>\n",
       "      <td>jury.n.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_idx                                            context  \\\n",
       "3              0  The Fulton said Friday an investigation of Atl...   \n",
       "7              0  The Fulton said Friday an investigation of Atl...   \n",
       "11             0  The Fulton said Friday an investigation of Atl...   \n",
       "14             0  The Fulton said Friday an investigation of Atl...   \n",
       "22             1  The jury further said in term end presentments...   \n",
       "23             1  The jury further said in term end presentments...   \n",
       "26             1  The jury further said in term end presentments...   \n",
       "27             1  The jury further said in term end presentments...   \n",
       "28             1  The jury further said in term end presentments...   \n",
       "39             1  The jury further said in term end presentments...   \n",
       "42             1  The jury further said in term end presentments...   \n",
       "44             1  The jury further said in term end presentments...   \n",
       "46             1  The jury further said in term end presentments...   \n",
       "53             1  The jury further said in term end presentments...   \n",
       "57             1  The jury further said in term end presentments...   \n",
       "59             1  The jury further said in term end presentments...   \n",
       "62             2  The September October term jury had been charg...   \n",
       "63             2  The September October term jury had been charg...   \n",
       "64             2  The September October term jury had been charg...   \n",
       "65             2  The September October term jury had been charg...   \n",
       "\n",
       "                                          context_pos target_word  \\\n",
       "3   The_DT Fulton_group said_say Friday_friday an_...          w3   \n",
       "7   The_DT Fulton_group said_say Friday_friday an_...          w7   \n",
       "11  The_DT Fulton_group said_say Friday_friday an_...         w11   \n",
       "14  The_DT Fulton_group said_say Friday_friday an_...         w14   \n",
       "22  The_DT jury_jury further_far said_say in_IN te...          w1   \n",
       "23  The_DT jury_jury further_far said_say in_IN te...          w2   \n",
       "26  The_DT jury_jury further_far said_say in_IN te...          w5   \n",
       "27  The_DT jury_jury further_far said_say in_IN te...          w6   \n",
       "28  The_DT jury_jury further_far said_say in_IN te...          w7   \n",
       "39  The_DT jury_jury further_far said_say in_IN te...         w18   \n",
       "42  The_DT jury_jury further_far said_say in_IN te...         w21   \n",
       "44  The_DT jury_jury further_far said_say in_IN te...         w23   \n",
       "46  The_DT jury_jury further_far said_say in_IN te...         w25   \n",
       "53  The_DT jury_jury further_far said_say in_IN te...         w32   \n",
       "57  The_DT jury_jury further_far said_say in_IN te...         w18   \n",
       "59  The_DT jury_jury further_far said_say in_IN te...         w38   \n",
       "62  The_DT September_september October_october ter...          w1   \n",
       "63  The_DT September_september October_october ter...          w2   \n",
       "64  The_DT September_september October_october ter...          w3   \n",
       "65  The_DT September_september October_october ter...          w4   \n",
       "\n",
       "            pos                                              gloss  \\\n",
       "3        friday   the sixth day of the week; the fifth working day   \n",
       "7       atlanta  state capital and largest city of Georgia; chi...   \n",
       "11      produce                              bring out for display   \n",
       "14     evidence  your basis for belief or disbelief; knowledge ...   \n",
       "22         jury  a body of citizens sworn to give a true verdic...   \n",
       "23          far         at or to or from a great distance in space   \n",
       "26         term                           a limited period of time   \n",
       "27          end          the point in time at which something ends   \n",
       "28  presentment  an accusation of crime made by a grand jury on...   \n",
       "39     election  a vote to select the winner of a position or p...   \n",
       "42      deserve                             be worthy or deserving   \n",
       "44       praise         an expression of approval and commendation   \n",
       "46       thanks                  an acknowledgment of appreciation   \n",
       "53       manner            how something is done or how it happens   \n",
       "57     election  a vote to select the winner of a position or p...   \n",
       "59      conduct            direct the course of; manage or control   \n",
       "62    september   the month following August and preceding October   \n",
       "63      october  the month following September and preceding No...   \n",
       "64         term                           a limited period of time   \n",
       "65         jury  a body of citizens sworn to give a true verdic...   \n",
       "\n",
       "    is_proper_gloss                  wn_index        sense_full  \n",
       "3              True             Friday%friday       friday.n.01  \n",
       "7              True           Atlanta%atlanta      atlanta.n.01  \n",
       "11             True          produced%produce      produce.v.04  \n",
       "14             True         evidence%evidence     evidence.n.01  \n",
       "22             True                 jury%jury         jury.n.01  \n",
       "23             True               further%far          far.r.02  \n",
       "26             True                 term%term         term.n.02  \n",
       "27             True                   end%end          end.n.02  \n",
       "28             True  presentments%presentment  presentment.n.01  \n",
       "39             True         election%election     election.n.01  \n",
       "42             True          deserves%deserve      deserve.v.01  \n",
       "44             True             praise%praise       praise.n.01  \n",
       "46             True             thanks%thanks       thanks.n.01  \n",
       "53             True             manner%manner       manner.n.01  \n",
       "57             True         election%election     election.n.01  \n",
       "59             True         conducted%conduct      conduct.v.01  \n",
       "62             True       September%september    september.n.01  \n",
       "63             True           October%october      october.n.01  \n",
       "64             True                 term%term         term.n.02  \n",
       "65             True                 jury%jury         jury.n.01  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"semcor_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home2/arjun.dosajh/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "def create_embeddings(sentences, tokenizer, model, max_length, batch_size=32):\n",
    "    embeddings = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i+batch_size]\n",
    "\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        # Tokenize each sentence and add special tokens for BERT\n",
    "        for sentence in batch_sentences:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                sentence,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_length,\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        # Convert the tokenized input into torch tensors\n",
    "        input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "\n",
    "        # Feed the input to BERT and get the embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_masks)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = create_embeddings(\n",
    "    X_train['context'], tokenizer, model, max_len)\n",
    "np.save('knn_bert4.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12208, 768)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/arjun.dosajh/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = create_embeddings(\n",
    "    X_test['context'], tokenizer, model, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = pd.DataFrame(columns=['file', 'context', 'target_word', 'gloss', 'is_proper_gloss','wn_index'])\n",
    "XTest = pd.DataFrame(columns=['file', 'context', 'target_word', 'gloss', 'is_proper_gloss','wn_index'])\n",
    "\n",
    "XTrain = pd.concat([XTrain, X_train], ignore_index=True)\n",
    "XTest = pd.concat([XTest, X_test], ignore_index=True)\n",
    "\n",
    "XTrain.head(10)\n",
    "\n",
    "cosine_similarities = []\n",
    "zero_cos = 0\n",
    "\n",
    "for i,test_embedding in enumerate(test_embeddings):\n",
    "    test_target_word = XTest.iloc[i]['wn_index']\n",
    "    train_rows = XTrain[XTrain['wn_index'] == test_target_word ]\n",
    "    for j,train_row in train_rows.iterrows():\n",
    "        train_embedding = embeddings[j]\n",
    "        similarity = np.dot(test_embedding, train_embedding) / (np.linalg.norm(test_embedding) * np.linalg.norm(train_embedding))\n",
    "        cosine_similarities.append(similarity)\n",
    "    if len(cosine_similarities) == 0:\n",
    "        zero_cos += 1\n",
    "    if len(cosine_similarities) > 0 :\n",
    "        # without using loc\n",
    "        XTest.at[i, 'cosine_similarity'] = max(cosine_similarities)\n",
    "    else:\n",
    "        # X_test.loc[X_test.index[i], 'cosine_similarity'] = -1\n",
    "        XTest.at[i, 'cosine_similarity'] = -1\n",
    "    cosine_similarities = []\n",
    "\n",
    "\n",
    "XTest['correct'] = XTest.apply(lambda row: row['gloss'] in XTrain[XTrain['wn_index']\n",
    "                                 == row['wn_index']].head(10)['gloss'].tolist(), axis=1)\n",
    "\n",
    "# # print the top-5 glosses of X_train for every X_test row \n",
    "X_test['top_5_glosses'] = X_test.apply(lambda row: X_train[X_train['wn_index'] == row['wn_index']].head(5)['gloss'].tolist(), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.75753604193972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "      <th>top_5_glosses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14046</th>\n",
       "      <td>2061</td>\n",
       "      <td>of minimal information can result only in show...</td>\n",
       "      <td>of_IN minimal_minimal information_information ...</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>having desirable or positive qualities especia...</td>\n",
       "      <td>True</td>\n",
       "      <td>good%good</td>\n",
       "      <td>good.a.01</td>\n",
       "      <td>[moral excellence or admirableness, having des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>147</td>\n",
       "      <td>Statements by other legislators that Dallas is...</td>\n",
       "      <td>Statements_statement by_IN other_other legisla...</td>\n",
       "      <td>w5</td>\n",
       "      <td>dallas</td>\n",
       "      <td>a large commercial and industrial city in nort...</td>\n",
       "      <td>True</td>\n",
       "      <td>Dallas%dallas</td>\n",
       "      <td>dallas.n.01</td>\n",
       "      <td>[a large commercial and industrial city in nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10508</th>\n",
       "      <td>1577</td>\n",
       "      <td>that sets him apart from all other bodybuilder...</td>\n",
       "      <td>that_IN sets_set him_PRP apart_apart from_IN a...</td>\n",
       "      <td>criterion</td>\n",
       "      <td>criterion</td>\n",
       "      <td>the ideal in terms of which something can be j...</td>\n",
       "      <td>True</td>\n",
       "      <td>criterion%criterion</td>\n",
       "      <td>criterion.n.02</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>656</td>\n",
       "      <td>a big night at bat with four hits in five incl...</td>\n",
       "      <td>a_DT big_big night_night at_NN bat_bat with_IN...</td>\n",
       "      <td>trips</td>\n",
       "      <td>trip</td>\n",
       "      <td>a journey for some purpose (usually including ...</td>\n",
       "      <td>True</td>\n",
       "      <td>trips%trip</td>\n",
       "      <td>trip.n.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7251</th>\n",
       "      <td>1201</td>\n",
       "      <td>all been done in superb style , and the result...</td>\n",
       "      <td>all_DT been_VBN done_VB in_VB superb_superb st...</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>be identical to; be someone or something</td>\n",
       "      <td>True</td>\n",
       "      <td>is%be</td>\n",
       "      <td>be.v.02</td>\n",
       "      <td>[have the quality of being; (copula, used with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>39</td>\n",
       "      <td>He will be succeeded by Ivan , who became a ca...</td>\n",
       "      <td>He_PRP will_MD be_VB succeeded_succeed by_IN I...</td>\n",
       "      <td>w18</td>\n",
       "      <td>announce</td>\n",
       "      <td>make known; make an announcement</td>\n",
       "      <td>True</td>\n",
       "      <td>announced%announce</td>\n",
       "      <td>announce.v.01</td>\n",
       "      <td>[make known; make an announcement, make known;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>69</td>\n",
       "      <td>Rep. of Commerce is asking the House in a priv...</td>\n",
       "      <td>Rep._person of_IN Commerce_group is_VBZ asking...</td>\n",
       "      <td>w16</td>\n",
       "      <td>support</td>\n",
       "      <td>the activity of providing for or maintaining b...</td>\n",
       "      <td>True</td>\n",
       "      <td>support%support</td>\n",
       "      <td>support.n.01</td>\n",
       "      <td>[the activity of providing for or maintaining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>1046</td>\n",
       "      <td>business , which ( considering the talent at )...</td>\n",
       "      <td>main_main business_business , _None which_WDT ...</td>\n",
       "      <td>probably</td>\n",
       "      <td>probably</td>\n",
       "      <td>with considerable certainty; without much doubt</td>\n",
       "      <td>True</td>\n",
       "      <td>probably%probably</td>\n",
       "      <td>probably.r.01</td>\n",
       "      <td>[with considerable certainty; without much dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13932</th>\n",
       "      <td>2043</td>\n",
       "      <td>four year provision limits this to fundamental...</td>\n",
       "      <td>the_DT four_four year_year provision_provision...</td>\n",
       "      <td>material</td>\n",
       "      <td>material</td>\n",
       "      <td>the tangible substance that goes into the make...</td>\n",
       "      <td>True</td>\n",
       "      <td>material%material</td>\n",
       "      <td>material.n.01</td>\n",
       "      <td>[information (data or ideas or observations) t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>936</td>\n",
       "      <td>saying we announced its coming , not once but ...</td>\n",
       "      <td>saying_say we_PRP announced_announce its_PRP $...</td>\n",
       "      <td>times</td>\n",
       "      <td>time</td>\n",
       "      <td>an instance or single occasion for some event</td>\n",
       "      <td>True</td>\n",
       "      <td>times%time</td>\n",
       "      <td>time.n.01</td>\n",
       "      <td>[an instance or single occasion for some event...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_idx                                            context  \\\n",
       "14046          2061  of minimal information can result only in show...   \n",
       "1035            147  Statements by other legislators that Dallas is...   \n",
       "10508          1577  that sets him apart from all other bodybuilder...   \n",
       "3954            656  a big night at bat with four hits in five incl...   \n",
       "7251           1201  all been done in superb style , and the result...   \n",
       "251              39  He will be succeeded by Ivan , who became a ca...   \n",
       "511              69  Rep. of Commerce is asking the House in a priv...   \n",
       "6277           1046  business , which ( considering the talent at )...   \n",
       "13932          2043  four year provision limits this to fundamental...   \n",
       "5678            936  saying we announced its coming , not once but ...   \n",
       "\n",
       "                                             context_pos target_word  \\\n",
       "14046  of_IN minimal_minimal information_information ...        good   \n",
       "1035   Statements_statement by_IN other_other legisla...          w5   \n",
       "10508  that_IN sets_set him_PRP apart_apart from_IN a...   criterion   \n",
       "3954   a_DT big_big night_night at_NN bat_bat with_IN...       trips   \n",
       "7251   all_DT been_VBN done_VB in_VB superb_superb st...          is   \n",
       "251    He_PRP will_MD be_VB succeeded_succeed by_IN I...         w18   \n",
       "511    Rep._person of_IN Commerce_group is_VBZ asking...         w16   \n",
       "6277   main_main business_business , _None which_WDT ...    probably   \n",
       "13932  the_DT four_four year_year provision_provision...    material   \n",
       "5678   saying_say we_PRP announced_announce its_PRP $...       times   \n",
       "\n",
       "             pos                                              gloss  \\\n",
       "14046       good  having desirable or positive qualities especia...   \n",
       "1035      dallas  a large commercial and industrial city in nort...   \n",
       "10508  criterion  the ideal in terms of which something can be j...   \n",
       "3954        trip  a journey for some purpose (usually including ...   \n",
       "7251          be           be identical to; be someone or something   \n",
       "251     announce                   make known; make an announcement   \n",
       "511      support  the activity of providing for or maintaining b...   \n",
       "6277    probably    with considerable certainty; without much doubt   \n",
       "13932   material  the tangible substance that goes into the make...   \n",
       "5678        time      an instance or single occasion for some event   \n",
       "\n",
       "       is_proper_gloss             wn_index      sense_full  \\\n",
       "14046             True            good%good       good.a.01   \n",
       "1035              True        Dallas%dallas     dallas.n.01   \n",
       "10508             True  criterion%criterion  criterion.n.02   \n",
       "3954              True           trips%trip       trip.n.01   \n",
       "7251              True                is%be         be.v.02   \n",
       "251               True   announced%announce   announce.v.01   \n",
       "511               True      support%support    support.n.01   \n",
       "6277              True    probably%probably   probably.r.01   \n",
       "13932             True    material%material   material.n.01   \n",
       "5678              True           times%time       time.n.01   \n",
       "\n",
       "                                           top_5_glosses  \n",
       "14046  [moral excellence or admirableness, having des...  \n",
       "1035   [a large commercial and industrial city in nor...  \n",
       "10508                                                 []  \n",
       "3954                                                  []  \n",
       "7251   [have the quality of being; (copula, used with...  \n",
       "251    [make known; make an announcement, make known;...  \n",
       "511    [the activity of providing for or maintaining ...  \n",
       "6277   [with considerable certainty; without much dou...  \n",
       "13932  [information (data or ideas or observations) t...  \n",
       "5678   [an instance or single occasion for some event...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = XTest['correct'].sum() / len(XTest)\n",
    "print(\"Accuracy: \", accuracy*100)\n",
    "X_test.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15260\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"semcor_temp.csv\")\n",
    "print(len(data))\n",
    "test_data = data[:500]\n",
    "train_data = data[500:]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# Compute BERT embeddings for each sentence and target word\n",
    "embeddings = []\n",
    "for i, row in data.iterrows():\n",
    "    context = row['context']\n",
    "    context_pos = row['context_pos']\n",
    "    # print(len(context_pos.split()))\n",
    "    target_word = row['sense_full']\n",
    "    gloss = row['gloss']\n",
    "    tokens = tokenizer.encode(context, target_word, add_special_tokens=False)\n",
    "    pos_tag_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    # shuffle the pos_tag_tokens list\n",
    "    np.random.shuffle(pos_tag_tokens)\n",
    "    gloss_tokens = tokenizer.encode(gloss, add_special_tokens=False)\n",
    "    tokens = tokens + [tokenizer.sep_token_id] + gloss_tokens \n",
    "\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    pos_tag_ids = torch.tensor(pos_tag_tokens).unsqueeze(0).to(device)\n",
    "    # Compute BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        context_embedding = output[0][0][1:-1].mean(dim=0).cpu()\n",
    "        pos_embedding = model(pos_tag_ids)[0][0][1:-1].mean(dim=0).cpu()\n",
    "\n",
    "    embedding = torch.cat([context_embedding, pos_embedding], dim=0).cpu().numpy()\n",
    "    embeddings.append(embedding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('naive_bert_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(embeddings)\n",
    "y_train = data['wn_index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = embeddings[:500]\n",
    "x_test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = {}\n",
    "likelihoods = {}\n",
    "y_test = test_data['wn_index'].values\n",
    "\n",
    "for sense in set(y_train):\n",
    "    sense_count = sum(y_train == sense)\n",
    "    # print(sense,sense_count)\n",
    "    prior_probs[sense] = sense_count / len(y_train)   \n",
    "    sense_embeddings = [x_train[i] for i in range(len(x_train)) if y_train[i] == sense]\n",
    "    likelihoods[sense] = np.mean(sense_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting labels:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting labels: 100%|██████████| 500/500 [40:15<00:00,  4.83s/it]\n",
      "Calculating accuracy: 100%|██████████| 500/500 [00:00<00:00, 289222.45it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i in tqdm(range(len(y_test)), desc=\"Predicting labels\", total=len(y_test)):\n",
    "    max_prob = 0\n",
    "    max_sense = None\n",
    "\n",
    "    for sense in set(y_train):\n",
    "        log_prob = prior_probs[sense]\n",
    "\n",
    "        for j in range(len(x_test[i])):\n",
    "            log_prob = log_prob + x_test[i][j] * likelihoods[sense][j]\n",
    "\n",
    "        if log_prob > max_prob:\n",
    "            max_prob = log_prob\n",
    "            max_sense = sense\n",
    "\n",
    "    y_pred.append(max_sense)\n",
    "\n",
    "correct = 0\n",
    "for i in tqdm(range(len(y_test)), desc=\"Calculating accuracy\", total=len(y_test)):\n",
    "    if y_pred[i] == y_test.tolist()[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.400000000000002\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad0a8d25012454fce516fd02556d13b58ba350644df31d02f07d47f8074eb7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
